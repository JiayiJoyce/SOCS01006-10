filtered_df <- df %>% filter(country %in% c("Brazil", "Turkey", "Argentina", "Afghanistan", "Belgium"))
create_point_plot <- function(i) {
filtered_df %>%
ggplot(aes_string(x = names(filtered_df)[2], y = names(filtered_df)[i])) +
geom_point() +
geom_smooth(method = "lm", se = TRUE, color = "blue") +  # Add trend lin
labs(
title = glue("The Trend of {names(df)[i]}"),
y = glue("{names(df)[i]}")
)
}
plots_list <- map(3:ncol(filtered_df), create_point_plot)
plots_grid <- gridExtra::grid.arrange(grobs = plots_list, ncol = 2) # Adjust ncol as needed
setwd("/Users/chenjiayi/Desktop/Computational/week04")
rm(list = ls())
#setup
if (!require("pacman")) {
install.packages("pacman")
}
pacman::p_load(
tidyverse, # tidyverse pkgs including purrr
kableExtra,#table
flextable, #table
glue, #combining strings and objects
ggplot2) #dataviz
options(scipen=999) #this is to avoid scientific notation in results
# importing data in .csv format
data <- read.csv("/Users/chenjiayi/Desktop/Computational/PublicRepoforSOCS0100Wk3/EMDAT.csv", header = TRUE)
# Subsetting and renaming data before automating the tasks
df <- data %>% select(Entity, Year, deaths_all_disasters, injured_all_disasters, homeless_all_disasters) %>%
rename(deaths = deaths_all_disasters, injuries = injured_all_disasters,
homelessness = homeless_all_disasters, country = Entity)
## Using purrr, please automate at least one data wrangling task based on the dataset
#(e.g. summarising data)
df %>%
select(-country, -Year) %>%  # Remove non numerical columns
map_dbl(mean, na.rm = TRUE)
## Using purrr please automate plotting the trends of deaths, injuries,
##and homelessness caused by all disasters for 5 countries in the dataset
filtered_df <- df %>% filter(country %in% c("Brazil", "Turkey", "Argentina", "Afghanistan", "Belgium"))
create_point_plot <- function(i) {
filtered_df %>%
ggplot(aes_string(x = names(filtered_df)[2], y = names(filtered_df)[i])) +
geom_point() +
geom_smooth(method = "lm", se = TRUE, color = "blue") +  # Add trend lin
labs(
title = glue("The Trend of {names(df)[i]}"),
y = glue("{names(df)[i]}")
)
}
plots_list <- map(3:ncol(filtered_df), create_point_plot)
plots_grid <- gridExtra::grid.arrange(grobs = plots_list, ncol = 2) # Adjust ncol as needed
setwd("/Users/chenjiayi/Desktop/Computational/week04")
rm(list = ls())
#setup
if (!require("pacman")) {
install.packages("pacman")
}
pacman::p_load(
tidyverse, # tidyverse pkgs including purrr
kableExtra,#table
flextable, #table
glue, #combining strings and objects
ggplot2) #dataviz
options(scipen=999) #this is to avoid scientific notation in results
# importing data in .csv format
data <- read.csv("/Users/chenjiayi/Desktop/Computational/PublicRepoforSOCS0100Wk3/EMDAT.csv", header = TRUE)
# Subsetting and renaming data before automating the tasks
df <- data %>% select(Entity, Year, deaths_all_disasters, injured_all_disasters, homeless_all_disasters) %>%
rename(deaths = deaths_all_disasters, injuries = injured_all_disasters,
homelessness = homeless_all_disasters, country = Entity)
## Using purrr, please automate at least one data wrangling task based on the dataset
#(e.g. summarising data)
df %>%
select(-country, -Year) %>%  # Remove non numerical columns
map_dbl(mean, na.rm = TRUE)
## Using purrr please automate plotting the trends of deaths, injuries,
##and homelessness caused by all disasters for 5 countries in the dataset
filtered_df <- df %>% filter(country %in% c("Brazil", "Turkey", "Argentina", "Afghanistan", "Belgium"))
create_point_plot <- function(i) {
filtered_df %>%
ggplot(aes_string(x = names(filtered_df)[2], y = names(filtered_df)[i])) +
geom_point() +
geom_smooth(method = "lm", se = TRUE, color = "blue") +  # Add trend lin
labs(
title = glue("The Trend of {names(df)[i]}"),
y = glue("{names(df)[i]}")
)
}
plots_list <- map(3:ncol(filtered_df), create_point_plot)
plots_grid <- gridExtra::grid.arrange(grobs = plots_list, ncol = 2) # Adjust ncol as needed
setwd("/Users/chenjiayi/Desktop/Computational/week04")
rm(list = ls())
#setup
if (!require("pacman")) {
install.packages("pacman")
}
pacman::p_load(
tidyverse, # tidyverse pkgs including purrr
kableExtra,#table
flextable, #table
glue, #combining strings and objects
ggplot2) #dataviz
options(scipen=999) #this is to avoid scientific notation in results
# importing data in .csv format
data <- read.csv("/Users/chenjiayi/Desktop/Computational/PublicRepoforSOCS0100Wk3/EMDAT.csv", header = TRUE)
# Subsetting and renaming data before automating the tasks
df <- data %>% select(Entity, Year, deaths_all_disasters, injured_all_disasters, homeless_all_disasters) %>%
rename(deaths = deaths_all_disasters, injuries = injured_all_disasters,
homelessness = homeless_all_disasters, country = Entity)
## Using purrr, please automate at least one data wrangling task based on the dataset
#(e.g. summarising data)
df %>%
select(-country, -Year) %>%  # Remove non numerical columns
map_dbl(mean, na.rm = TRUE)
## Using purrr please automate plotting the trends of deaths, injuries,
##and homelessness caused by all disasters for 5 countries in the dataset
filtered_df <- df %>% filter(country %in% c("Brazil", "Turkey", "Argentina", "Afghanistan", "Belgium"))
create_point_plot <- function(i) {
filtered_df %>%
ggplot(aes_string(x = names(filtered_df)[2], y = names(filtered_df)[i])) +
geom_point() +
geom_smooth(method = "lm", se = TRUE, color = "blue") +  # Add trend lin
labs(
title = glue("The Trend of {names(df)[i]}"),
y = glue("{names(df)[i]}")
)
}
plots_list <- map(3:ncol(filtered_df), create_point_plot)
plots_grid <- gridExtra::grid.arrange(grobs = plots_list, ncol = 2) # Adjust ncol as needed
ggThemeAssist:::ggThemeAssistAddin()
ggThemeAssist:::ggThemeAssistAddin()
ggThemeAssist:::ggThemeAssistAddin()
#remove everything in your environment and setting up directory
setwd("/Users/chenjiayi/Desktop/Computational/PublicRepoforSOCS0100Wk3")
rm(list = ls())
#setup
if (!require("pacman")) {
install.packages("pacman")
}
pacman::p_load(
tidyverse, # tidyverse pkgs including purrr
kableExtra,#table
flextable, #table
skimr) #a broad overview of data frame
data <- read.csv("EMDAT.csv", header = TRUE)
# 3) Inspect the data briefly and identify its structure
#tip: to avoid all scientific notation (e numbers) by setting options(scipen=999) at the top of the script
skim(data)
df <- data %>% select(Entity, Year, deaths_all_disasters, injured_all_disasters, homeless_all_disasters) %>%
rename(deaths = deaths_all_disasters, injuries = injured_all_disasters,
homelessness = homeless_all_disasters, country = Entity)
glimpse(df)
# Calculate the averages
averages <- df %>%
filter(!country %in% c("World", "Soviet Union")) %>%  # Remove "World" and "Soviet Union"
group_by(country) %>%
summarise(
avg_deaths = mean(deaths, na.rm = TRUE),
avg_injuries = mean(injuries, na.rm = TRUE),
avg_homelessness = mean(homelessness, na.rm = TRUE)
)
# Create tables for the top 10 averages
top_10_deaths <- averages %>%
arrange(desc(avg_deaths)) %>%
head(10) %>%
kable(caption = "Top 10 Countries by Average Deaths")
# Apply formatting
top_10_deaths %>%
kable_styling("striped") %>%
kable_classic(full_width = FALSE)
top_10_injuries <- averages %>%
arrange(desc(avg_injuries)) %>%
head(10) %>%
kable(caption = "Top 10 Countries by Average Injuries")
top_10_injuries %>%
kable_styling("striped") %>%
kable_classic(full_width = FALSE)
top_10_homelessness <- averages %>%
arrange(desc(avg_homelessness)) %>%
head(10) %>%
kable(caption = "Top 10 Countries by Average Homelessness")
top_10_homelessness %>%
kable_styling("striped") %>%
kable_classic(full_width = FALSE)
df <- df %>% mutate(high_death = ifelse(deaths > 500, 1, 0))
# 7) Reshape the dataset (selected version) and save it as a separate dataset in your repository
df_wide <- df %>%
pivot_wider(
names_from = Year,       # Specify the columns to pivot
values_from = c(deaths, injuries, homelessness, high_death)  # Specify the values columns
)
# Save the df_wide data frame as a separate R data set
saveRDS(df_wide, "df_wide.rds")
# 0. Set up: installing packages, remove the # in front of them to run-----
#set working directory
setwd("/Users/chenjiayi/Desktop/Computational/DVHZ3-SOCS0100-Assignment")
#clearing environment
rm(list = ls())
#install Groundhog if it is not installed, remove # to run
if (!require("groundhog")) {
install.packages("groundhog")
}
#creating the vector pkgs that include all the packages needed for the following task
pkgs <- c("tidyverse",
"kableExtra",
"flextable",
"skimr",
"ggplot2",
"glue",
"janitor",
"countrycode")
# install packages as they are available on 2023-11-04, remove # to install
groundhog.library(pkgs, "2023-11-04")
# Create an interactive choropleth map
plot_ly(
locations = iso_country,
z = total_money_by_country$money,
text = paste("Country: ", total_money_by_country$country, "<br>Net Worth: $", total_money_by_country$money, "B"),
type = "choropleth",
colorscale = "Viridis"
) %>%
layout(
title = "Billionaires' Wealth Distribution by Country",
geo = list(
showframe = FALSE,
projection = list(type = 'mercator')
)
)
rm(list=ls())
# Setup
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
RSelenium,
rvest,
purrr,
dplyr,
ggplot2,
plotly,
countrycode
)
# Connecting to browser
driver <- rsDriver(browser = "firefox")
remote_driver <- driver$client
# Navigating to the page
url <- "https://www.forbes.com/real-time-billionaires"
remote_driver$navigate(url)
rm(list=ls())
pacman::p_load(
RSelenium,
rvest,
purrr,
dplyr,
ggplot2,
plotly,
countrycode,
ggmap,
httr,
gtrendsR
)
GET("https://trends.google.com/trends/explore",
query=list(q = "Humanitarian",geo = "GB"))
data("countries") # get abbreviations of all countries to filter data
data("categories") # get numbers of all categories to filter data
#Combination using dplyr and ggplot
trend <- gtrends(keyword="vaccine", geo=c("GB"), time = "2021-01-01 2021-12-30", gprop="web")
trend_df <- trend$interest_over_time
trend_df <- trend_df %>%
mutate(hits = as.numeric(hits), date = as.Date(date)) %>%
replace(is.na(.), 0)
ggplot(trend_df, aes(x=date, y=hits, group=geo, col=geo)) + geom_line(size=2) +
scale_x_date(date_breaks = "2 months" , date_labels = "%b-%y") +
labs(color= "Countries") +
ggtitle("Frequencies for the query -vaccine harm- in the period: 2021-01-01 - 2021-12-3")
#if gtrendsR package doesn't work, try trendecon package
library(trendecon)
GET("https://trends.google.com/trends/explore",
query=list(q = "Humanitarian",geo = "GB"))
# put a vector for the geo part
data("countries") # get abbreviations of all countries to filter data
data("categories") # get numbers of all categories to filter data
#Combination using dplyr and ggplot
trend <- gtrends(keyword="vaccine", geo=c("GB"), time = "2021-01-01 2021-12-30", gprop="web")
#web: what type of search enquiries
trend_df <- trend$interest_over_time
trend_df <- trend_df %>%
mutate(hits = as.numeric(hits), date = as.Date(date)) %>%
replace(is.na(.), 0)
ggplot(trend_df, aes(x=date, y=hits, group=geo, col=geo)) + geom_line(size=2) +
scale_x_date(date_breaks = "2 months" , date_labels = "%b-%y") +
labs(color= "Countries") +
ggtitle("Frequencies for the query -vaccine harm- in the period: 2021-01-01 - 2021-12-3")
library(trendecon)
pacman::p_load(
RSelenium,
rvest,
purrr,
dplyr,
ggplot2,
plotly,
countrycode,
ggmap,
httr,
gtrendsR,
trendecon
)
remotes::install_github("trendecon/trendecon")
pacman::p_load(
RSelenium,
rvest,
purrr,
dplyr,
ggplot2,
plotly,
countrycode,
ggmap,
httr,
gtrendsR,
osmdata,
leaflet
)
library(trendecon)
x <- ts_gtrends(keyword = c("vaccine fraud", "vaccine danger"), geo = c("GB"), time = "today+5-y",
retry = 5,
wait = 10,
colour="lightpink")
library(trendecon)
x <- ts_gtrends(keyword = c("vaccine fraud", "vaccine danger"), geo = c("GB"), time = "today+5-y",
retry = 5,
wait = 10)
tsbox::ts_plot(x)
bb <- getbb ("london uk")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "amenity", value = "pub") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
bb <- getbb ("london uk")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "amenity", value = "pub") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
bb <- getbb ("london uk")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "amenity", value = "pub") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
bb <- getbb ("london uk")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "amenity", value = "bar") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
rm(list=ls())
# Setup
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
RSelenium,
rvest,
purrr,
dplyr,
ggplot2,
plotly,
countrycode,
ggmap,
httr,
gtrendsR,
osmdata,
leaflet
)
remotes::install_github("trendecon/trendecon")
bb <- getbb ("london uk")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "amenity", value = "pub") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
bb <- getbb ("london uk")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "office", value = "charity") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
View(bb)
View(london_rst)
bb <- getbb ("london uk")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "office", value = "charity") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
bb <- getbb ("london uk")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "office", value = "charity") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
bb <- getbb ("london uk")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "amenity", value = "pub") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
head(london_rst$osm_polygons)$name
#select name and geometry for charities
rst_osm_points <- london_rst$osm_points %>% #select point data from downloaded OSM data
select(name, geometry) #for now just selecting the name and geometry to plot
rst_osm_polygons <- london_rst$osm_polygons %>%
select(name, geometry)
london_charities <- rbind(rst_osm_points, rst_osm_polygons)
leaflet() %>%
addPolygons(
data = london_rst$osm_polygons,
label = london_rst$osm_polygons$name
) %>%
addCircles(
data = london_rst$osm_points,
label = london_rst$osm_points$name
) %>%
addProviderTiles("CartoDB.Positron")
bb <- getbb ("shanghai china")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "amenity", value = "bar") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
bb <- getbb ("shanghai china")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "amenity", value = "bar") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
bb <- getbb ("shanghai china")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "amenity", value = "university") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
head(london_rst$osm_polygons)$name
#select name and geometry for charities
rst_osm_points <- london_rst$osm_points %>% #select point data from downloaded OSM data
select(name, geometry) #for now just selecting the name and geometry to plot
rst_osm_polygons <- london_rst$osm_polygons %>%
select(name, geometry)
london_charities <- rbind(rst_osm_points, rst_osm_polygons)
leaflet() %>%
addPolygons(
data = london_rst$osm_polygons,
label = london_rst$osm_polygons$name
) %>%
addCircles(
data = london_rst$osm_points,
label = london_rst$osm_points$name
) %>%
addProviderTiles("CartoDB.Positron")
bb <- getbb ("shanghai china")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "amenity", value = "kindergarten") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
head(london_rst$osm_polygons)$name
#select name and geometry for charities
rst_osm_points <- london_rst$osm_points %>% #select point data from downloaded OSM data
select(name, geometry) #for now just selecting the name and geometry to plot
rst_osm_polygons <- london_rst$osm_polygons %>%
select(name, geometry)
london_charities <- rbind(rst_osm_points, rst_osm_polygons)
leaflet() %>%
addPolygons(
data = london_rst$osm_polygons,
label = london_rst$osm_polygons$name
) %>%
addCircles(
data = london_rst$osm_points,
label = london_rst$osm_points$name
) %>%
addProviderTiles("CartoDB.Positron")
head(london_rst$osm_polygons)$name
#select name and geometry for charities
rst_osm_points <- london_rst$osm_points %>% #select point data from downloaded OSM data
select(name, geometry) #for now just selecting the name and geometry to plot
rst_osm_polygons <- london_rst$osm_polygons %>%
select(name, geometry)
london_charities <- rbind(rst_osm_points, rst_osm_polygons)
leaflet() %>%
addPolygons(
data = london_rst$osm_polygons,
label = london_rst$osm_polygons$name
) %>%
addCircles(
data = london_rst$osm_points,
label = london_rst$osm_points$name
) %>%
addProviderTiles("CartoDB.Positron")
bb <- getbb ("beijing china")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "amenity", value = "kindergarten") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
bb <- getbb ("beijing china")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "amenity", value = "kindergarten") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
bb <- getbb ("beijing china")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "amenity", value = "kindergarten") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
bb <- getbb ("beijing china")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "amenity", value = "kindergarten") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
bb <- getbb ("beijing china")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "amenity", value = "kindergarten") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
bb <- getbb ("beijing china")
london_rst <- opq(bb) %>% #gets bounding box
add_osm_feature(key = "amenity", value = "kindergarten") %>% #searches for charities
osmdata_sf() #download OSM data as sf (simple features -- spatial data format in R)
head(london_rst$osm_polygons)$name
#select name and geometry for charities
rst_osm_points <- london_rst$osm_points %>% #select point data from downloaded OSM data
select(name, geometry) #for now just selecting the name and geometry to plot
rst_osm_polygons <- london_rst$osm_polygons %>%
select(name, geometry)
london_charities <- rbind(rst_osm_points, rst_osm_polygons)
leaflet() %>%
addPolygons(
data = london_rst$osm_polygons,
label = london_rst$osm_polygons$name
) %>%
addCircles(
data = london_rst$osm_points,
label = london_rst$osm_points$name
) %>%
addProviderTiles("CartoDB.Positron")
